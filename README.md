<div align="center">

# ⚡️Target-Driven Distillation⚡️

[![arXiv](https://img.shields.io/badge/arXiv-coming%20soon-b31b1b.svg?logo=arxiv)](https://arxiv.org)
[![Hugging Face Models](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-blue)](https://huggingface.co/RedAIGC/TDD)

</div>

Target-Driven Distillation (TDD) is a state-of-the-art consistency distillation model that largely accelerates the inference processes of diffusion models. Using its delicate strategies of *target timestep selection* and *decoupled guidance*, models distilled by TDD can generated highly detailed images with only a few steps.

Images below are samples generated by TDD-distilled SDXL, with only 4--8 steps.

<div align="center">
  <img src="assets/teaser.jpg" alt="teaser" style="zoom:80%;" />
</div>



## News

- **Aug. 22, 2024**: Project in progress, comming soon.


## Usage

### Inference

- Download pretrained models from here: [![Hugging Face Models](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-blue)](https://huggingface.co/RedAIGC/TDD)

- Follow the generation script below.

```python
# !pip install opencv-python transformers accelerate 
import diffusers
from diffusers import StableDiffusionXLPipeline
from tdd_scheduler import TDDSchedulerPlus

device = "cuda"
tdd_lora_path = "tdd_lora/sdxl_tdd_lora_weights.safetensors"

pipe = StableDiffusionXLPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0", 
    torch_dtype=torch.float16, 
    variant="fp16").to(device)

pipe.scheduler = TDDSchedulerPlus.from_config(pipe.scheduler.config)
pipe.load_lora_weights(tdd_lora_path, adapter_name="accelerate")
pipe.fuse_lora()

prompt = "analog film photo of a man. faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage, masterpiece, best quality"

image = pipe(
    prompt=prompt,
    num_inference_steps=4,
    guidance_scale=1,
    eta=0.2, 
    generator=torch.Generator(device=device).manual_seed(0),
).images[0]

image.save("tdd.png")
```


## Introduction

Target-Driven Distillation (TDD) features three key designs, that differ from previous consistency distillation methods.
1. **TDD adopts a delicate selection strategy of target timesteps, increasing the training efficiency.** Specifically, it first chooses from a predefined set of equidistant denoising schedules (*e.g.* 4--8 steps), then adds a stochatic offset to accomodate non-deterministic sampling (*e.g.* $\gamma$-sampling).
2. **TDD utilizes decoupled guidances during training, making itself open to post-tuning on guidance scale during inference periods.** Specifically, it replaces a portion of the text conditions with unconditional (*i.e.* empty) prompts, in order to align with the standard training process using CFG.
3. **TDD can be optionally equipped with non-equidistant sampling and x0 clipping, enabling a more flexible and accurate way for image sampling.**

<div align="center">
  <img src="assets/tdd_overview.jpg" alt="overview" width="500" />
</div>

Images below are samples generated by SDXL models distilled by mainstream consistency distillation methods LCM, PCM, TCD, and our TDD, from the same seeds.

<div align="center">
  <img src="assets/compare.jpg" alt="comparison" style="zoom:80%;" />
</div>


For details of TDD, please refer to our paper
> **Target-Driven Distillation: Consistency Distillation with Target Timestep Selection and Decoupled Guidance**<br>
> Cunzheng Wang, Ziyuan Guo, Yuxuan Duan, Huaxia Li, Nemo Chen, Xu Tang, Yao Hu<br>
>
> [![arXiv](https://img.shields.io/badge/arXiv-coming%20soon-b31b1b.svg?logo=arxiv)](https://arxiv.org)<br>



## Concact, Collaboration, and Citation

If you have any questions about the code, please do not hesitate to contact me!

Email: polu@xiaohongshu.com

If you find TDD helpful to your research, please cite our paper:
```
@article{Wang2024TDD,
  title     = {Target-Driven Distillation: Consistency Distillation with Target Timestep Selection and Decoupled Guidance},
  author    = {Cunzheng Wang and Ziyuan Guo and Yuxuan Duan and Huaxia Li and Nemo Chen and Xu Tang and Yao Hu},
  journal   = {arXiv preprint arXiv:xxxx.xxxxx},
  year      = {2024}
}
```
